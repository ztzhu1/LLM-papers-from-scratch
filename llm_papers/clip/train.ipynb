{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e4f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sub_project_dir = Path(os.path.abspath(''))\n",
    "project_dir = sub_project_dir.parent\n",
    "sys.path.insert(0, project_dir.parent.as_posix())\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from llm_papers.clip.dataset import load_cifar100, load_coco2017\n",
    "from llm_papers.clip.model import CLIP, load_pretrained_roberta, load_pretrained_vit\n",
    "from llm_papers.utils import device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af74b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, pretrained_text_model = load_pretrained_roberta()\n",
    "transform, pretrained_vision_model = load_pretrained_vit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61479189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (text_model): Roberta(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embed): Embedding(50265, 768, padding_idx=1)\n",
       "      (pos_embed): Embedding(514, 768, padding_idx=1)\n",
       "      (type_embed): Embedding(1, 768, padding_idx=0)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vision_model): ViT(\n",
       "    (patch_embed): ViTPatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
       "    )\n",
       "    (pos_embed): ViTPosEmbed()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm_attn): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm_mlp): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (text_proj): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (vision_proj): Linear(in_features=768, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CLIP()\n",
    "model.load(pretrained_text_model, pretrained_vision_model)\n",
    "model.freeze()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63536ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_coco = load_coco2017(transform, tokenizer)\n",
    "train_dataset_cifar, test_dataset = load_cifar100(transform, tokenizer)\n",
    "data_collator_pad = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    (text_logits, image_logits), labels = eval_pred\n",
    "    image_predictions = np.argmax(image_logits, -1)\n",
    "\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    results = accuracy.compute(predictions=image_predictions, references=labels)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def data_collator(features):\n",
    "    batch = {}\n",
    "    for key in features[0]:\n",
    "        if key in [\"input_ids\", \"attention_mask\"]:\n",
    "            continue\n",
    "        batch[key] = torch.stack([f[key] for f in features])\n",
    "    if \"input_ids\" not in features[0]:\n",
    "        batch[\"input_ids\"] = test_dataset.input_ids\n",
    "        batch[\"attention_mask\"] = test_dataset.attention_mask\n",
    "    else:\n",
    "        text_batch = data_collator_pad(\n",
    "            [\n",
    "                {\"input_ids\": f[\"input_ids\"], \"attention_mask\": f[\"attention_mask\"]}\n",
    "                for f in features\n",
    "            ]\n",
    "        )\n",
    "        batch.update(text_batch)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7521b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "def model_init():\n",
    "    model.init_weights()\n",
    "    return model\n",
    "\n",
    "\n",
    "lr = 5e-4\n",
    "batch_size = 256\n",
    "gradient_accumulation_steps = 8\n",
    "epochs = 5\n",
    "wd = 0.0\n",
    "logging_steps = 5\n",
    "eval_steps = 100\n",
    "save_steps = 100\n",
    "report_to = \"wandb\"\n",
    "train_coco = False\n",
    "if train_coco:\n",
    "    train_ds_name = \"coco2017\"\n",
    "    train_dataset = train_dataset_coco\n",
    "else:\n",
    "    train_ds_name = \"cifar100\"\n",
    "    train_dataset = train_dataset_cifar\n",
    "output_dir = (\n",
    "    sub_project_dir\n",
    "    / \"checkpoints\"\n",
    "    / f\"distilroberta_vit_b_32_224_{train_ds_name}_lr{lr}_ep{epochs}_bs{batch_size}_wd{wd}\"\n",
    ")\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "os.environ[\"WANDB_ENTITY\"] = \"ztzhu11\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"CLIP\"\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir.as_posix(),\n",
    "    per_device_train_batch_size=batch_size // gradient_accumulation_steps,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    num_train_epochs=epochs,\n",
    "    learning_rate=lr,\n",
    "    lr_scheduler_type=\"cosine_with_min_lr\",\n",
    "    lr_scheduler_kwargs={\"min_lr_rate\": 0.1},\n",
    "    weight_decay=wd,\n",
    "    max_grad_norm=5,\n",
    "    seed=42,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_on_start=True,\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_steps=eval_steps,\n",
    "    dataloader_num_workers=8,\n",
    "    dataloader_prefetch_factor=4,\n",
    "    dataloader_persistent_workers=True,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    log_level=\"info\",\n",
    "    logging_first_step=True,\n",
    "    logging_steps=logging_steps,\n",
    "    report_to=report_to,\n",
    "    run_name=output_dir.name,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    None,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    model_init=model_init,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fd1a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 50,000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 980\n",
      "  Number of trainable parameters = 787,457\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mztzhu1\u001b[0m (\u001b[33mztzhu11\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/LLM-papers-from-scratch/llm_papers/clip/wandb/run-20251205_011442-m0jnd1ov</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ztzhu11/CLIP/runs/m0jnd1ov' target=\"_blank\">distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0</a></strong> to <a href='https://wandb.ai/ztzhu11/CLIP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ztzhu11/CLIP' target=\"_blank\">https://wandb.ai/ztzhu11/CLIP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ztzhu11/CLIP/runs/m0jnd1ov' target=\"_blank\">https://wandb.ai/ztzhu11/CLIP/runs/m0jnd1ov</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not log the number of model parameters in Weights & Biases due to an AttributeError.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [980/980 06:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.604990</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.025100</td>\n",
       "      <td>1.561237</td>\n",
       "      <td>0.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.717400</td>\n",
       "      <td>0.961037</td>\n",
       "      <td>0.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.788277</td>\n",
       "      <td>0.812800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>0.686301</td>\n",
       "      <td>0.827100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.636011</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.607316</td>\n",
       "      <td>0.842200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.452800</td>\n",
       "      <td>0.597921</td>\n",
       "      <td>0.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.422200</td>\n",
       "      <td>0.571849</td>\n",
       "      <td>0.847100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.562375</td>\n",
       "      <td>0.849300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-100\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-200\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-100] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-300\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-200] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-400\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-300] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-400] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-600\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-500] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-700\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-600] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-800\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-700] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-900\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-800] due to args.save_total_limit\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-980\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-900 (score: 0.8493).\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0/checkpoint-980] due to args.save_total_limit\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇███████</td></tr><tr><td>eval/loss</td><td>█▃▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁▂▃▄▄▄▄▄</td></tr><tr><td>eval/samples_per_second</td><td>▁█▇▇▆▅▅▅▅▄</td></tr><tr><td>eval/steps_per_second</td><td>▁█▇▇▆▅▅▅▅▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▁▁▂▅▇▇▆▅▇▅▆█▇▅▅▆▅▅▅▅▅▅▅▆▅▄▅▅▅▆▆▅▅▅▄▅▅▅▄▅</td></tr><tr><td>train/learning_rate</td><td>██████▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▄▃▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8493</td></tr><tr><td>eval/loss</td><td>0.56238</td></tr><tr><td>eval/runtime</td><td>11.7985</td></tr><tr><td>eval/samples_per_second</td><td>847.566</td></tr><tr><td>eval/steps_per_second</td><td>13.307</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>980</td></tr><tr><td>train/grad_norm</td><td>5.63026</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distilroberta_vit_b_32_224_cifar100_lr0.0005_ep5_bs256_wd0.0</strong> at: <a href='https://wandb.ai/ztzhu11/CLIP/runs/m0jnd1ov' target=\"_blank\">https://wandb.ai/ztzhu11/CLIP/runs/m0jnd1ov</a><br> View project at: <a href='https://wandb.ai/ztzhu11/CLIP' target=\"_blank\">https://wandb.ai/ztzhu11/CLIP</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251205_011442-m0jnd1ov/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    if report_to == \"wandb\":\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7577f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 118,287\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 2,315\n",
      "  Number of trainable parameters = 787,457\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mztzhu1\u001b[0m (\u001b[33mztzhu11\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/LLM-papers-from-scratch/llm_papers/clip/wandb/run-20251205_004255-75zwg93p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ztzhu11/CLIP/runs/75zwg93p' target=\"_blank\">distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0</a></strong> to <a href='https://wandb.ai/ztzhu11/CLIP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ztzhu11/CLIP' target=\"_blank\">https://wandb.ai/ztzhu11/CLIP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ztzhu11/CLIP/runs/75zwg93p' target=\"_blank\">https://wandb.ai/ztzhu11/CLIP/runs/75zwg93p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not log the number of model parameters in Weights & Biases due to an AttributeError.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2315' max='2315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2315/2315 27:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.604990</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.008400</td>\n",
       "      <td>3.549900</td>\n",
       "      <td>0.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.722700</td>\n",
       "      <td>3.352227</td>\n",
       "      <td>0.202800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>3.233922</td>\n",
       "      <td>0.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>3.176095</td>\n",
       "      <td>0.239400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>3.156679</td>\n",
       "      <td>0.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>3.106933</td>\n",
       "      <td>0.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.482600</td>\n",
       "      <td>3.103880</td>\n",
       "      <td>0.253200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>3.091398</td>\n",
       "      <td>0.252400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>3.045178</td>\n",
       "      <td>0.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>3.051582</td>\n",
       "      <td>0.260700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>3.069263</td>\n",
       "      <td>0.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>3.036845</td>\n",
       "      <td>0.263600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>3.039754</td>\n",
       "      <td>0.263300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>3.028745</td>\n",
       "      <td>0.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>3.025949</td>\n",
       "      <td>0.267100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>3.040882</td>\n",
       "      <td>0.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>3.027989</td>\n",
       "      <td>0.270100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>3.029405</td>\n",
       "      <td>0.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>3.012910</td>\n",
       "      <td>0.273300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>3.029788</td>\n",
       "      <td>0.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>3.011465</td>\n",
       "      <td>0.275400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>3.013064</td>\n",
       "      <td>0.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>3.008005</td>\n",
       "      <td>0.277300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-100\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-900] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-200\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-100] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-300\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-200] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-400\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-300] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-400] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-600\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-500] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-700\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-600] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-800\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-900\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-800] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1100\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1000] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1200\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-900] due to args.save_total_limit\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1100] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1300\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1400\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1200] due to args.save_total_limit\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1300] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1400] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1600\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1700\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1600] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1800\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1900\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1700] due to args.save_total_limit\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1800] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2100\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-1900] due to args.save_total_limit\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2000] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2200\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2300\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2100] due to args.save_total_limit\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2200] due to args.save_total_limit\n",
      "Saving model checkpoint to /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2315\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2300 (score: 0.2773).\n",
      "Deleting older checkpoint [/workspace/LLM-papers-from-scratch/llm_papers/clip/checkpoints/distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0/checkpoint-2315] due to args.save_total_limit\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▇▇▇▇▇▇██▇████████████</td></tr><tr><td>eval/loss</td><td>█▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▁▂▁▂▂▃▄▄▃▂▃█▃▄▃▄▄▅▃▃▅▅▄</td></tr><tr><td>eval/samples_per_second</td><td>▅█▇█▇▇▆▅▅▆▇▅▁▅▅▆▅▅▄▆▆▄▄▅</td></tr><tr><td>eval/steps_per_second</td><td>▅█▇█▇▇▆▅▅▆▇▅▁▅▅▆▅▅▄▆▆▄▄▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▁▁▅▆▅▅█▇▇▅▆▅▆▆▅▅▆▆▅▇▆▆▅▅▇▅▆▆▄▆▅▆▅▅▅▅▆▆▄▆</td></tr><tr><td>train/learning_rate</td><td>██████████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.2773</td></tr><tr><td>eval/loss</td><td>3.00801</td></tr><tr><td>eval/runtime</td><td>12.2012</td></tr><tr><td>eval/samples_per_second</td><td>819.59</td></tr><tr><td>eval/steps_per_second</td><td>12.868</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2315</td></tr><tr><td>train/grad_norm</td><td>13.88826</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distilroberta_vit_b_32_224_coco2017_lr0.0005_ep5_bs256_wd0.0</strong> at: <a href='https://wandb.ai/ztzhu11/CLIP/runs/75zwg93p' target=\"_blank\">https://wandb.ai/ztzhu11/CLIP/runs/75zwg93p</a><br> View project at: <a href='https://wandb.ai/ztzhu11/CLIP' target=\"_blank\">https://wandb.ai/ztzhu11/CLIP</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251205_004255-75zwg93p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    if report_to == \"wandb\":\n",
    "        wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
